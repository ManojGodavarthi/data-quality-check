{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b0022aa-b7b3-4665-aff4-3cc9d624bd1e",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a2b5b7-57e6-4feb-b688-f71c3343fcf2",
   "metadata": {},
   "source": [
    "This document provides a step by step guide to perform a comprehensive Data Quality Check on public data source.\n",
    "Examining the completeness, accuracy, consistency, validity, uniqueness, and integrity of data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9ddb11-c990-426e-9476-c786f1d227f4",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0822c1e-6a4b-4c17-baa2-304cad3b83e5",
   "metadata": {},
   "source": [
    "Programming Knowledge:\n",
    "\n",
    "Proficiency in Python and familiarity with Jupyter Notebook or an IDE.\n",
    "Libraries/Packages:\n",
    "\n",
    "pandas: For data manipulation (e.g., handling missing data, filtering, data transformation).\n",
    "numpy: For numerical operations, handling NaN values, and array manipulations.\n",
    "matplotlib & seaborn: For creating visualizations to detect patterns, trends, and outliers.\n",
    "plotly.express: For interactive visualizations, especially useful in exploring large datasets.\n",
    "sklearn.impute (SimpleImputer): For handling missing values by imputing (filling) with various strategies.\n",
    "Data Cleaning Techniques:\n",
    "\n",
    "Handling missing data (SimpleImputer and custom imputation techniques).\n",
    "Outlier detection and handling (through visualizations).\n",
    "Data transformation techniques like normalization or encoding, if applicable.\n",
    "Exploratory Data Analysis (EDA) for insight generation.\n",
    "Basic Data Science Skills:\n",
    "\n",
    "Familiarity with statistics (mean, median, standard deviation) for understanding data distributions.\n",
    "Knowledge of common data issues, like multicollinearity or categorical encoding needs.\n",
    "Project Setup:\n",
    "\n",
    "Organize code, document steps and transformations, and save important visualizations for future reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75121dd6-a4bc-4ed1-80ca-78e66b6e2e5c",
   "metadata": {},
   "source": [
    "## Steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735c634b-0ff0-460c-b4ec-b801d4d3d2d2",
   "metadata": {},
   "source": [
    "press ctrl+enter to run the script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a01b48-4c7f-40e2-b234-459900497b10",
   "metadata": {},
   "source": [
    "### import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "189621fc-ca51-4b90-a3b0-a6648b1d8dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98da7804-edc6-41f3-a428-96dec21420ce",
   "metadata": {},
   "source": [
    "## Download the dataset from Kaggle\n",
    "1. Open Kaggle and navigate to https://www.kaggle.com/datasets/vikrishnan/iris-dataset\n",
    "2. Click Download\n",
    "3. Extract iris.data.csv file\n",
    "4. import the iris.data.csv file to jupyter\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b89b3d-97a2-450b-b28d-095036e07ca9",
   "metadata": {},
   "source": [
    "## import dataset \n",
    "use pandas.read_csv(): passs the file path of your CSV file to this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00155fc5-d32f-49ce-bdac-58922f8c5a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"Load the dataset into a Pandas DataFrame.\"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        print(f\"Dataset loaded successfully. Shape: {data.shape}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b9529e-94cb-472e-8462-68361740e528",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "#### count of missing value per column\n",
    "#### df.isnull() - create a dataframe of same shape as df which contains true if original value is null otherwise false\n",
    "#### sum() - total count of missing values for each column in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8eb405f2-c4b6-4bcb-81dc-918d0def945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_values(df):\n",
    "    \"\"\"Check for missing values in each column.\"\"\"\n",
    "    missing_values = df.isnull().sum()\n",
    "    missing_values = missing_values[missing_values > 0]\n",
    "    if not missing_values.empty:\n",
    "        print(\"\\nMissing Values:\")\n",
    "        print(missing_values)\n",
    "    else:\n",
    "        print(\"\\nNo missing values found.\")\n",
    "    return missing_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a6b50f-bde5-4f4e-98ff-36017f1cd4cb",
   "metadata": {},
   "source": [
    "## Dublicate rows \n",
    "identify dublicate rows in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d76eda3-aa94-41fd-bf3b-e322c31e8fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicates(df):\n",
    "    \"\"\"Check for duplicate rows in the dataset.\"\"\"\n",
    "    duplicate_rows = df[df.duplicated()]\n",
    "    if not duplicate_rows.empty:\n",
    "        print(f\"\\nFound {duplicate_rows.shape[0]} duplicate rows.\")\n",
    "    else:\n",
    "        print(\"\\nNo duplicate rows found.\")\n",
    "    return duplicate_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110b6e8e-a4d0-4c01-8ef7-1f78e5a53e69",
   "metadata": {},
   "source": [
    "## Outliers Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba640191-2de8-4238-9a3d-8d33d8a09142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers(df, threshold=3):\n",
    "    \"\"\"Detect outliers in numerical columns using Z-score.\"\"\"\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    outliers = {}\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        z_scores = np.abs(stats.zscore(df[col]))\n",
    "        outliers[col] = df[col][z_scores > threshold]\n",
    "    \n",
    "    for col, outlier_values in outliers.items():\n",
    "        if not outlier_values.empty:\n",
    "            print(f\"\\nOutliers detected in column {col}:\")\n",
    "            print(outlier_values)\n",
    "        else:\n",
    "            print(f\"\\nNo outliers found in column {col}.\")\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cfc9ed-cb08-4298-a362-787d9cee6c4c",
   "metadata": {},
   "source": [
    "## Generate reporte rows.\\n\\n\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2cf8de2-58fd-4ca5-8223-5c35ec646294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(missing_values, duplicate_rows, outliers):\n",
    "    \"\"\"Generate a summary report of the data quality checks.\"\"\"\n",
    "    with open(\"data_quality_report.txt\", \"w\") as report_file:\n",
    "        report_file.write(\"Data Quality Check Report\\n\")\n",
    "        report_file.write(\"=========================\\n\\n\")\n",
    "        \n",
    "        report_file.write(\"Missing Values:\\n\")\n",
    "        if not missing_values.empty:\n",
    "            report_file.write(f\"{missing_values}\\n\\n\")\n",
    "        else:\n",
    "            report_file.write(\"No missing values found.\\n\\n\")\n",
    "        \n",
    "        report_file.write(\"Duplicate Rows:\\n\")\n",
    "        if not duplicate_rows.empty:\n",
    "            report_file.write(f\"Found {duplicate_rows.shape[0]} duplicate rows.\\n\\n\")\n",
    "        else:\n",
    "            report_file.write(\"No duplicate rows found.\\n\\n\")\n",
    "        \n",
    "        report_file.write(\"Outliers:\\n\")\n",
    "        for col, outlier_values in outliers.items():\n",
    "            if not outlier_values.empty:\n",
    "                report_file.write(f\"Outliers in column {col}:\\n\")\n",
    "                report_file.write(f\"{outlier_values}\\n\\n\")\n",
    "            else:\n",
    "                report_file.write(f\"No outliers found in column {col}.\\n\\n\")\n",
    "\n",
    "        print(\"\\nSummary report generated: data_quality_report.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e389c48-2316-4614-9955-0561478b4cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully. Shape: (149, 5)\n",
      "\n",
      "No missing values found.\n",
      "\n",
      "Found 3 duplicate rows.\n",
      "\n",
      "No outliers found in column 5.1.\n",
      "\n",
      "Outliers detected in column 3.5:\n",
      "14    4.4\n",
      "Name: 3.5, dtype: float64\n",
      "\n",
      "No outliers found in column 1.4.\n",
      "\n",
      "No outliers found in column 0.2.\n",
      "\n",
      "Summary report generated: data_quality_report.txt\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load dataset\n",
    "    dataset_path = 'iris.data.csv'\n",
    "    df = load_data(dataset_path)\n",
    "    \n",
    "    if df is not None:\n",
    "        # Perform data quality checks\n",
    "        missing_values = check_missing_values(df)\n",
    "        duplicate_rows = check_duplicates(df)\n",
    "        outliers = detect_outliers(df)\n",
    "\n",
    "        # Generate the report\n",
    "        generate_report(missing_values, duplicate_rows, outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c342e80d-d5f4-4e21-84cf-e8b42da7f509",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
